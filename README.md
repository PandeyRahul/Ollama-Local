# Ollama-Local
This is my repo in which I am working on running Llama models locally with multiple data sources.
